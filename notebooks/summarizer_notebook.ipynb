{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec68790b",
   "metadata": {},
   "source": [
    "# JS-Aware Web Summarizer (Selenium + OpenAI)\n",
    "Short, fast summaries from static or JS pages. Uses headless Chrome when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e00a20",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- Keep `OPENAI_API_KEY` in env.\n",
    "- Uses `requests` first; falls back to Selenium if page seems JS-heavy or `--force-js`.\n",
    "- Caches raw HTML and summaries.\n",
    "- CLI included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d7ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal imports (install first run)\n",
    "# !pip install selenium webdriver-manager beautifulsoup4 lxml python-dotenv readability-lxml tiktoken --quiet\n",
    "import os, re, time, json, hashlib, pathlib, html\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from readability import Document\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Config (edit as needed) ----\n",
    "CACHE_DIR = pathlib.Path(\"cache\"); CACHE_DIR.mkdir(exist_ok=True)\n",
    "TIMEOUT = 20\n",
    "MAX_TOKENS = 1200   # tighten for cheaper runs\n",
    "MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "USER_AGENT = \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5513ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _key(s: str) -> str: return hashlib.sha256(s.encode()).hexdigest()[:16]\n",
    "\n",
    "def cache_write(name: str, data: bytes):\n",
    "    p = CACHE_DIR / name; p.write_bytes(data); return p\n",
    "\n",
    "def cache_read(name: str) -> Optional[bytes]:\n",
    "    p = CACHE_DIR / name\n",
    "    return p.read_bytes() if p.exists() else None\n",
    "\n",
    "def strip_noise(html_text: str) -> str:\n",
    "    # quick clean; keep it short\n",
    "    soup = BeautifulSoup(html_text, \"lxml\")\n",
    "    for tag in soup([\"script\",\"style\",\"noscript\"]): tag.extract()\n",
    "    return soup.get_text(\" \", strip=True)\n",
    "\n",
    "def looks_js_heavy(html_text: str) -> bool:\n",
    "    # heuristic: lots of script tags or empty body text\n",
    "    scripts = len(re.findall(r'<script[\\s>]', html_text, flags=re.I))\n",
    "    return scripts > 20 or len(strip_noise(html_text)) < 400\n",
    "\n",
    "def short(txt: str, n=9000) -> str:\n",
    "    return txt[:n] + (\"â€¦\" if len(txt) > n else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07821a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FetchResult:\n",
    "    url: str\n",
    "    method: str\n",
    "    html: str\n",
    "    text: str\n",
    "    elapsed: float\n",
    "\n",
    "def fetch_static(url: str) -> FetchResult:\n",
    "    t0 = time.time()\n",
    "    r = requests.get(url, headers={\"User-Agent\": USER_AGENT}, timeout=TIMEOUT)\n",
    "    r.raise_for_status()\n",
    "    html_text = r.text\n",
    "    elapsed = time.time() - t0\n",
    "    return FetchResult(url, \"requests\", html_text, strip_noise(html_text), elapsed)\n",
    "\n",
    "def fetch_selenium(url: str, wait_css: Optional[str]=None) -> FetchResult:\n",
    "    t0 = time.time()\n",
    "    opts = Options()\n",
    "    opts.add_argument(\"--headless=new\")\n",
    "    opts.add_argument(\"--no-sandbox\")\n",
    "    opts.add_argument(\"--disable-gpu\")\n",
    "    opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    opts.add_argument(f\"--user-agent={USER_AGENT}\")\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(), options=opts)\n",
    "    try:\n",
    "        driver.set_page_load_timeout(TIMEOUT)\n",
    "        driver.get(url)\n",
    "        if wait_css:\n",
    "            WebDriverWait(driver, min(TIMEOUT, 15)).until(EC.presence_of_element_located((By.CSS_SELECTOR, wait_css)))\n",
    "        html_text = driver.page_source\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    elapsed = time.time() - t0\n",
    "    return FetchResult(url, \"selenium\", html_text, strip_noise(html_text), elapsed)\n",
    "\n",
    "def smart_fetch(url: str, force_js=False, wait_css: Optional[str]=None) -> FetchResult:\n",
    "    # cache first\n",
    "    ck = f\"raw_{_key(url)}.html\"\n",
    "    cached = cache_read(ck)\n",
    "    if cached:\n",
    "        html_text = cached.decode(\"utf-8\", errors=\"ignore\")\n",
    "        return FetchResult(url, \"cache\", html_text, strip_noise(html_text), 0.0)\n",
    "    try:\n",
    "        if not force_js:\n",
    "            s = fetch_static(url)\n",
    "            # if static works and doesn't look JS-heavy, use it\n",
    "            if not looks_js_heavy(s.html):\n",
    "                cache_write(ck, s.html.encode(\"utf-8\", errors=\"ignore\"))\n",
    "                return s\n",
    "        # else fallback\n",
    "        s = fetch_selenium(url, wait_css=wait_css)\n",
    "        cache_write(ck, s.html.encode(\"utf-8\", errors=\"ignore\"))\n",
    "        return s\n",
    "    except Exception as e:\n",
    "        # last resort: try selenium if static failed, or static if selenium failed\n",
    "        if force_js:\n",
    "            alt = fetch_static(url)\n",
    "        else:\n",
    "            alt = fetch_selenium(url, wait_css=wait_css)\n",
    "        cache_write(ck, alt.html.encode(\"utf-8\", errors=\"ignore\"))\n",
    "        return alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a9b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_content(html_text: str, url: str) -> Tuple[str, str]:\n",
    "    try:\n",
    "        doc = Document(html_text)\n",
    "        title = doc.short_title()\n",
    "        clean_html = doc.summary(html_partial=True)\n",
    "        text = strip_noise(clean_html)\n",
    "        return title, text\n",
    "    except Exception:\n",
    "        return \"\", strip_noise(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0762c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def approx_tokens(s: str, model: str=\"gpt-4o-mini\") -> int:\n",
    "    try:\n",
    "        enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        return len(enc.encode(s))\n",
    "    except Exception:\n",
    "        return len(s)//4\n",
    "\n",
    "def summarize(text: str, url: str, model: str = MODEL, max_tokens: int = MAX_TOKENS) -> str:\n",
    "    import http.client, json, os\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not api_key: raise RuntimeError(\"Set OPENAI_API_KEY in env\")\n",
    "    system = \"Be concise. 6 bullets max. Include 1 line TL;DR. Use plain text.\"\n",
    "    user = f\"Source: {url}\\n\\nContent:\\n{text}\"\n",
    "    body = json.dumps({\n",
    "        \"model\": model,\n",
    "        \"input\": [\n",
    "            {\"role\":\"system\",\"content\":system},\n",
    "            {\"role\":\"user\",\"content\":user}\n",
    "        ],\n",
    "        \"max_output_tokens\": max_tokens\n",
    "    })\n",
    "    conn = http.client.HTTPSConnection(\"api.openai.com\")\n",
    "    conn.request(\"POST\", \"/v1/responses\", body=body, headers={\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    })\n",
    "    resp = conn.getresponse()\n",
    "    data = json.loads(resp.read())\n",
    "    conn.close()\n",
    "    # extract text\n",
    "    try:\n",
    "        return data[\"output\"][0][\"content\"][0][\"text\"]\n",
    "    except Exception:\n",
    "        return json.dumps(data, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a8083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_url(url: str, force_js=False, wait_css=None, max_chars=18000) -> dict:\n",
    "    fetched = smart_fetch(url, force_js=force_js, wait_css=wait_css)\n",
    "    title, main_text = extract_main_content(fetched.html, url)\n",
    "    text = short(main_text, n=max_chars)\n",
    "    summ = summarize(text, url)\n",
    "    out = {\n",
    "        \"url\": url,\n",
    "        \"title\": title or \"(no title)\",\n",
    "        \"method\": fetched.method,\n",
    "        \"elapsed_sec\": round(fetched.elapsed, 2),\n",
    "        \"summary\": summ.strip(),\n",
    "    }\n",
    "    # cache summary\n",
    "    cache_write(f\"sum_{_key(url)}.json\", json.dumps(out, ensure_ascii=False, indent=2).encode())\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e59c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cli():\n",
    "    import argparse, sys\n",
    "    p = argparse.ArgumentParser(description=\"Short JS-aware web summarizer\")\n",
    "    p.add_argument(\"url\", help=\"Page to summarize\")\n",
    "    p.add_argument(\"--force-js\", action=\"store_true\", help=\"Force Selenium\")\n",
    "    p.add_argument(\"--wait-css\", default=None, help=\"CSS selector to wait for\")\n",
    "    p.add_argument(\"--print\", action=\"store_true\", help=\"Print summary to stdout\")\n",
    "    args = p.parse_args()\n",
    "    out = summarize_url(args.url, force_js=args.force_js, wait_css=args.wait_css)\n",
    "    path = CACHE_DIR / f\"sum_{_key(args.url)}.json\"\n",
    "    print(f\"Saved: {path}\")\n",
    "    if args.print:\n",
    "        print(\"\\n== Summary ==\\n\", out[\"summary\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example (uncomment to try):\n",
    "    # print(summarize_url(\"https://example.com\", force_js=False))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591001e6",
   "metadata": {},
   "source": [
    "**Run**\n",
    "```bash\n",
    "# 1) Create venv; install deps\n",
    "pip install -r requirements.txt\n",
    "# or:\n",
    "pip install selenium webdriver-manager beautifulsoup4 lxml readability-lxml tiktoken python-dotenv\n",
    "\n",
    "# 2) Env\n",
    "export OPENAI_API_KEY=***\n",
    "\n",
    "# 3) Notebook\n",
    "# Run cells; or use CLI from a .py export.\n",
    "\n",
    "# 4) CLI (optional)\n",
    "python js_summarizer.py \"https://example.com\" --force-js --print\n",
    "```\n",
    "\n",
    "**Make it yours**\n",
    "- Add logo + short demo GIF.\n",
    "- Include `samples/` with 2 static and 2 JS sites.\n",
    "- Keep summaries <= 6 bullets; one TL;DR."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}